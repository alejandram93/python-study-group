{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV1GLLVXdBSq"
   },
   "source": [
    "###### References: \n",
    "- https://docs.python.org/3/tutorial/datastructures.html   \n",
    "- Fluent Python by Luciano Ramalho. Chapter 4: Text versus Bytes\n",
    "\n",
    "\n",
    "# Character Issues\n",
    "## Unicode \n",
    "The Unicode standard separates the identity of characters from specific byte representations.\n",
    "* The character id, i.e. _code point_, is a number from 0 to 1,114,111 in the Unicode standdard\n",
    "* U+ prefix\n",
    "* The actual bytes depend on the _encoding_, e.g. `A` (U+0041) is encoded as a single byte in UTF-8, `\\x41`, or as `\\x41\\x00` in UTF-16LE  encoding.\n",
    "\n",
    "#### Encoding and decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'cafe'\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = s.encode('utf8')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.decode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Byte Essentials\n",
    "## `bytes` or `bytearray`\n",
    "Each item is an integer from 0 to 255, and not a one character string.\n",
    "\n",
    " `bytes` object is immutable; `bytearray` object allows you to modify its elements.\n",
    "#### A five-byte sequence as  bytes and bytearray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe = bytes('cafe', encoding='utf-8')\n",
    "cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe_arr = bytearray(cafe)\n",
    "cafe_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe_arr[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building bytes and  bytearray\n",
    "#### `fromhex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes.fromhex('31 48 CE A9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* using a `str` and an `encoding`\n",
    "* An iterable providing items with values from 0 to 255\n",
    "* An object that implements the buffer protocol  (e.g. `bytes`, `bytearray`, `memoryview`, `array.array`);  this copies the bytes from the source object to the newly created binary sequence\n",
    "####  Initializing bytes from the raw data of  an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "\n",
    "numbers = array.array('h', [-2, -1, 0, 1, 2])\n",
    "octets = bytes(numbers)\n",
    "octets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a `bytes` or `bytearray` from any buffer-like source will always copy the bytes. In contract, `memoryview` objects let you share memory between binary data structures.\n",
    "# Structs and Memory Views\n",
    "`struct` module provides functions to parse packed bytes into a tuple of fields of different types of different types and to perform the opposite conversion.\n",
    "\n",
    "`memoryview` class does not let you create or store byte sequences, but provides a shared memory access to   slices of data from other binary sequnences, etc, without copying the bytes.\n",
    "\n",
    "####  Using  `memoryview` and `struct` to inspect a GIF image header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "fmt = '<3s3sHH' # struct format: < little endian;3s3s two sequences of 3 bytes; HH two 16-bit integers;\n",
    "\n",
    "with open('20220219/women_who_code.gif', 'rb') as fp:\n",
    "    img = memoryview(fp.read())\n",
    "    \n",
    "header = img[:10]\n",
    "bytes(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct.unpack(fmt, header) # type, version, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del header\n",
    "del img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ref: https://docs.python.org/3/library/mmap.html\n",
    "\n",
    "# Basic Encoders / Decoders\n",
    "\n",
    "The Python distribution bundles more than 100 _codecs_ for text to byte conversion and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for codec in ['latin_1', 'utf_8', 'utf_16']:\n",
    "    print(codec, \"El Niño\".encode(codec), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Encode/Decode Problems\n",
    "###  Coping with UnicodeEncodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"São Paulo\"\n",
    "city.encode('utf_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city.encode('utf_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city.encode('iso8859_1')  # \"Latin alphabet no. 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city.encode('cp437')  # character set of the original IBM PC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city.encode('cp437', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city.encode('cp437', errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city.encode('cp437', errors='xmlcharrefreplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Coping with UnicodeDecodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octets = b'Monter\\xe9al'\n",
    "octets.decode('cp1252')  # Windows-1252 is a single-byte character encoding of the Latin alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octets.decode('iso8859_7')  # Part 7: Latin/Greek alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octets.decode('koi8_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octets.decode('utf_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octets.decode('utf_8', errors='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SyntaxError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 20220219/hello.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover Encoding\n",
    "### Chardet\n",
    "Character Encodding Detector\n",
    "\n",
    "https://pypi.python.org/pypi/chardet\n",
    "\n",
    "### BOM\n",
    "byte-order-mark\n",
    "\n",
    "UTF-16 encodings prepends text to be encoded with `ZERO WIDTH NO-BREAK SPACE` U+FEFF.\n",
    "\n",
    "Such that little-endian system is encoded as `'\\xff\\xfe'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u16 = 'Olá Mundo'.encode('utf_16')\n",
    "u16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u16le = 'Olá Mundo'.encode('utf_16le')\n",
    "list(u16le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u16be = 'Olá Mundo'.encode('utf_16be')\n",
    "list(u16be)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Text Files\n",
    "##  The Unicode Sandwich\n",
    "* Decode bytes on input\n",
    " *  process text only\n",
    "* Encode text on output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('cafe.txt', 'w', encoding='utf_8').write('café')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('cafe.txt', encoding='cp1252').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('cafe.txt')\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write size and encoded file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.stat('cafe.txt').st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp2 = open('cafe.txt')\n",
    "fp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp2.encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading in binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp3 = open('cafe.txt', 'rb')\n",
    "fp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp3.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressions  = \"\"\"\n",
    "        locale.getpreferredencoding()\n",
    "        type(my_file)\n",
    "        my_file.encoding\n",
    "        sys.stdout.isatty()\n",
    "        sys.stdout.encoding\n",
    "        sys.stdin.isatty()\n",
    "        sys.stdin.encoding\n",
    "        sys.stderr.isatty()\n",
    "        sys.stderr.encoding\n",
    "        sys.getdefaultencoding()\n",
    "        sys.getfilesystemencoding()\n",
    "        \"\"\"\n",
    "\n",
    "my_file = open('dummy', 'w')\n",
    "\n",
    "for expression in expressions.split():\n",
    "    value = eval(expression)\n",
    "    print(expression.rjust(30), '->', repr(value))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Unicode for saner comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "s1, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s1), len(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normalize('NFC', s1)), len(normalize('NFC', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normalize('NFD', s1)), len(normalize('NFD', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize('NFC', s1) == normalize('NFC', s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize('NFD', s1) == normalize('NFD', s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain characters are similar, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohm = '\\u2126'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name(ohm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohm_c  = normalize('NFC', ohm)\n",
    "name(ohm_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohm == ohm_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize('NFC', ohm) == normalize('NFC', ohm_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compatibility in characters\n",
    "NFKC  , NFKD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half =  '½'\n",
    "normalize('NFKC', half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_squared = '4²'\n",
    "normalize('NFKC', four_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro = 'µ'\n",
    "micro_kc = normalize('NFKD', micro)\n",
    "micro, micro_kc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord(micro), ord(micro_kc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name(micro), name(micro_kc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise with care. In some cases, it is useful for indexing and searching.\n",
    "\n",
    "## Case folding\n",
    "`s.casefold()` is converting all text to lowercase, with some additional transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name(micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_cf = micro.casefold()\n",
    "name(micro_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro, micro_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eszett = 'ß'\n",
    "name(eszett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eszett_cf = eszett.casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eszett, eszett_cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions for Normalized Text Matching\n",
    "For most cases, `str.casefold()` is good for case-insensitive comparison.\n",
    "\n",
    "If you work with text in many languages, creating a pair of functions like `nfc_equal` and `fold_equal` are useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfc_equal(str1, str2):\n",
    "    return normalize('NFC', str1) == normalize('NFC', str2)\n",
    "\n",
    "def fold_equal(str1, str2):\n",
    "    return (normalize('NFC', str1).casefold() ==\n",
    "            normalize('NFC', str2).casefold())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 == s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfc_equal(s1,  s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfc_equal('a', 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_equal('a', 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street1 = 'Straße'\n",
    "street2 = 'strasse'\n",
    "street1 == street2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfc_equal(street1, street2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_equal(street1, street2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme \"Normalization\":  Take  out  Diacritics\n",
    "Diacritics are __marks placed above or below__ (or sometimes next to) a letter in a word to indicate a particular pronunciation—in regard to accent, tone, or stress—as well as meaning\n",
    "\n",
    "Google search ignores diacritics, (e.g. accents, cedillas, etc.), in certain contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"Remove all diacritic marks\"\"\"\n",
    "    norm_text = unicodedata.normalize('NFD', txt)  # Decompose characters into base char and combining marks\n",
    "    shaved = ''.join(c for c  in norm_text if not unicodedata.combining(c)) # Filter out combining marks\n",
    "    return unicodedata.normalize('NFC', shaved) # Recompose all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "shave_marks(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greek = 'Ζέφυρος, Zéfiro'\n",
    "shave_marks(greek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shave_marks_latin(txt):\n",
    "    \"\"\"Remove all diacritic marks from Latin base characters\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)  \n",
    "    latin_base = False\n",
    "    keepers = []\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:   # Skip over combining marks when base char is Latin\n",
    "            continue  # ignore diacritic on Latin base char\n",
    "        keepers.append(c)                             # Otherwise keep current char\n",
    "        # if it isn't combining char, it's a new base char\n",
    "        if not unicodedata.combining(c):              # Detect new base char and dertermine if it's Latin\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = ''.join(keepers)\n",
    "    return unicodedata.normalize('NFC', shaved)   # Recompose all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shave_marks_latin(greek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_map = str.maketrans(\"\"\"‚ƒ„†ˆ‹‘’“”•–—˜›\"\"\",  # Build mapping table for char-to-char replacement\n",
    "                           \"\"\"'f\"*^<''\"\"---~>\"\"\")\n",
    "\n",
    "multi_map = str.maketrans({  # Build mapping table for char-to-string replacement\n",
    "    '€': '<euro>',\n",
    "    '…': '...',\n",
    "    'Œ': 'OE',\n",
    "    '™': '(TM)',\n",
    "    'œ': 'oe',\n",
    "    '‰': '<per mille>',\n",
    "    '‡': '**',\n",
    "})\n",
    "\n",
    "multi_map.update(single_map)  # Merge mapping tables\n",
    "\n",
    "\n",
    "def dewinize(txt):\n",
    "    \"\"\"Replace Win1252 symbols with ASCII chars or sequences\"\"\"\n",
    "    return txt.translate(multi_map)  # does not affect ASCII or latin1 text\n",
    "\n",
    "\n",
    "def asciize(txt):\n",
    "    no_marks = shave_marks_latin(dewinize(txt))     # Remove diacritical marks\n",
    "    no_marks = no_marks.replace('ß', 'ss')          # We want to preserve the case\n",
    "    return unicodedata.normalize('NFKC', no_marks)  # Recompose with compatibility codepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shave_marks_latin(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dewinize(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asciize(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Sorting Unicode Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = ['Cupuaçu', 'Açaí', 'Acerola', 'Cajá', 'Caju']\n",
    "sorted(fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_COLLATE,  'pt_BR.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(fruits, key=locale.strxfrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting with Unicode Collation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyuca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll = pyuca.Collator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(fruits, key=coll.sort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Unicode Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_digit = re.compile(r'\\d')\n",
    "\n",
    "sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in sample:\n",
    "    print('U+%04x' % ord(char),                       # Code point in U+0000 format\n",
    "          char.center(6),                             # Characterized in str len of 6\n",
    "          're_dig' if re_digit.match(char) else '-',  # Show re_dig if character matches the regex\n",
    "          'isdig' if char.isdigit() else '-',         # Show isdig if char.isdigit()\n",
    "          'isnum' if char.isnumeric() else '-',       # Show isnum if char.isnumeric()\n",
    "          format(unicodedata.numeric(char), '5.2f'),  # Numeric value formated, width 5 and 2 decimal place\n",
    "          unicodedata.name(char),                     # Unicode character name\n",
    "          sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual-Mode str and bytes APIs\n",
    "## `str` Versus `bytes` in Regular Expressions\n",
    "Hardy–Ramanujan number 1729 : the smallest number expressible as the sum of two cubes in two different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re_numbers_str = re.compile(r'\\d+')     # String types\n",
    "re_words_str = re.compile(r'\\w+')\n",
    "re_numbers_bytes = re.compile(rb'\\d+')  # Byte types\n",
    "re_words_bytes = re.compile(rb'\\w+')\n",
    "\n",
    "text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\"  # Unicodde text to search, contining Tamil digits 1729\n",
    "            \" as 1729 = 1³ + 12³ = 9³ + 10³.\")        # String literal concatenation\n",
    "\n",
    "text_bytes = text_str.encode('utf_8')  # bytes string is needed to search with the bytes regular expression\n",
    "\n",
    "print('Text', repr(text_str), sep='\\n  ')\n",
    "print('Numbers')\n",
    "print('  str  :', re_numbers_str.findall(text_str))      # The str pattern r'\\d+' matches the Tamil and ASCII\n",
    "print('  bytes:', re_numbers_bytes.findall(text_bytes))  # The bytes pattern rb'\\d+' matches only ASCII digits\n",
    "print('Words')\n",
    "print('  str  :', re_words_str.findall(text_str))        # The str pattern r'\\w+' matches letters, superscripts, Tamil, and ASCII digits.\n",
    "print('  bytes:', re_words_bytes.findall(text_bytes))    # The bytes pattern rb'\\w+' matches only ASCII bytes for letters and  digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expression can be used on `str` as well as `bytes`.\n",
    "\n",
    "`re` on `bytes` outside of the ASCII range are treated as nondigits and nonword characters.\n",
    "\n",
    "## `str` Versus `bytes` on `os` Functions\n",
    "\n",
    "`listdir` with `str` and `bytes` arguments and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('20220219/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(b'20220219/')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "20220205 Dictionaries and Sets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
